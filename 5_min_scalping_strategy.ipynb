{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.youtube.com/watch?v=wbfXaqjIrJ0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.8/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "GBP_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(491385, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "EUR_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_USD_M5/2016-01-01_2022-07-31.csv\n",
      "(490023, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_USD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "USD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(490422, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "EUR_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(490530, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "AUD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(491484, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "CAD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(491481, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "CHF_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CHF_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "(491222, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CHF_JPY_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "GBP_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_USD_M5/2016-01-01_2022-07-31.csv\n",
      "(489547, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_USD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "USD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "(489821, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "USD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "(482326, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "AUD_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_USD_M5/2016-01-01_2022-07-31.csv\n",
      "(486874, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_USD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "NZD_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_USD_M5/2016-01-01_2022-07-31.csv\n",
      "(489200, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_USD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "AUD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "(491449, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "AUD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "(490455, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "AUD_NZD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_NZD_M5/2016-01-01_2022-07-31.csv\n",
      "(490938, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_NZD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "CAD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "(490050, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "EUR_AUD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_AUD_M5/2016-01-01_2022-07-31.csv\n",
      "(490696, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_AUD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "EUR_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "(491389, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "EUR_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "(489208, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "NZD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "(491429, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CAD_M5/2016-01-01_2022-07-31.csv\n",
      "\n",
      "NZD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "(490624, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CHF_M5/2016-01-01_2022-07-31.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "!pip install plotly\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "import time\n",
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import time \n",
    "import os\n",
    "def create_data_and_save(instrument,start,end,pair,hours = 3,granularity = \"M1\"):\n",
    "\n",
    "    print('CREATING DATASET...')\n",
    "    s = time.time()\n",
    "    print('PARAMS:',start,end,pair,granularity)\n",
    "    cur = start\n",
    "\n",
    "    #i = 'GBP_JPY'\n",
    "    total_df = 0\n",
    "    dct = {}\n",
    "    \n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    \n",
    "    isdir = os.path.isdir(dir_name) \n",
    "    if isdir:\n",
    "        pass\n",
    "    else:\n",
    "        print('MAKING DIRECTORY:',dir_name)\n",
    "        os.mkdir(dir_name) \n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    while cur < end:\n",
    "        print(cur)    \n",
    "        df = convert_to_simple_df(instrument = instrument,granularity = granularity,count = 5000,start = cur,end = cur + timedelta(hours = hours))\n",
    "        \n",
    "\n",
    "        cur = cur + timedelta(hours = hours)\n",
    "\n",
    "        print(df.shape)\n",
    "        if df.shape[1] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total_df = total_df.append(df)\n",
    "            except:\n",
    "                total_df = df\n",
    "                \n",
    "            dct[str(cur)] = df\n",
    "\n",
    "    print(total_df.shape)\n",
    "    total_df.to_csv(path,index = False)\n",
    "    e = time.time()\n",
    "    print('TOTAL DATASET CONSTRUCTION TIME:',(e-s)/60,' MINUTES')\n",
    "    \n",
    "    \n",
    "def smma(df,period = 14):\n",
    "    print('GETTING SMMA INDICATOR FOR:',period)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['smma_' + str(period)] = df['c']\n",
    "    smma_col = df.columns.get_loc('smma_' + str(period))\n",
    "    arr = df.values\n",
    "    \n",
    "    #SMMA CALC:\n",
    "    \n",
    "    #SUM1=SUM (CLOSE, N)\n",
    "\n",
    "    #SMMA1 = SUM1/ N\n",
    "\n",
    "    #The second and subsequent moving averages are calculated according to this formula:\n",
    "\n",
    "    #SMMA (i) = (SUM1 – SMMA1+CLOSE (i))/ N    \n",
    "    \n",
    "   # Where:\n",
    "\n",
    "    #SUM1 – is the total sum of closing prices for N periods;\n",
    "    #SMMA1 – is the smoothed moving average of the first bar;\n",
    "    #SMMA (i) – is the smoothed moving average of the current bar (except the first one);\n",
    "    #CLOSE (i) – is the current closing price;\n",
    "    #N – is the smoothing period.    \n",
    "\n",
    "    for i in range(period,arr.shape[0]):\n",
    "        if i == period:\n",
    "            sum1 = sum(arr[:i,close_col])\n",
    "\n",
    "            smma1 = sum1 / period\n",
    " \n",
    "            arr[i,smma_col] = smma1\n",
    "        elif i == period + 1:\n",
    "            arr[i,smma_col] = (smma1 * (period - 1) + arr[i,close_col]) / period\n",
    "            \n",
    "        else:\n",
    "\n",
    "            prev_sum = arr[i - 1,smma_col] * period\n",
    "            arr[i,smma_col] = (prev_sum - arr[i - 1,smma_col] + arr[i,close_col]) / period\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def ema(df,num = 14):\n",
    "    print('GETTING EMA INDICATOR FOR:',num)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['ema_' + str(num)] = df['c']\n",
    "    arr = df.values\n",
    "    mult = 2/ (num + 1)\n",
    "    for i in range(num,arr.shape[0]):\n",
    "        sma = sum(arr[i - num + 1: i + 1,close_col]) / num\n",
    "        arr[i,-1] = ((arr[i,close_col] - arr[i - 1,-1]) * mult) + arr[i - 1,-1]\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def engulfing_candle(df):\n",
    "    print('GETTING ENGULFING CANDLES...')\n",
    "    df['bearish_engulfing'] = 0\n",
    "    df['bullish_engulfing'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_engulfing')\n",
    "    col2 = df.columns.get_loc('bullish_engulfing')\n",
    "    \n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        obp = arr[i-1,open_col] #open[1]\n",
    "        cbp = arr[i-1,close_col] #close[1]\n",
    "        obc = arr[i,open_col] #open\n",
    "        cbc = arr[i,close_col] #close        \n",
    "        #If current bar open is less than equal to the previous bar close AND current bar open is less than previous bar open AND current bar close is greater than previous bar open THEN True\n",
    "        if obc <= cbp and obc < obp and cbc > obp:\n",
    "            arr[i,col2] = 1\n",
    "        \n",
    "        #If current bar open is greater than equal to previous bar close AND current bar open is greater than previous bar open AND current bar close is less than previous bar open THEN True\n",
    "        elif obc >= cbp and obc > obp and cbc < obp:    \n",
    "            arr[i,col1] = 1\n",
    "        \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "\n",
    "def three_line_strike(df):\n",
    "    print('GETTING 3 LINE STRIKE...')\n",
    "    df['bearish_tls'] = 0\n",
    "    df['bullish_tls'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_tls')\n",
    "    col2 = df.columns.get_loc('bullish_tls')\n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(4,arr.shape[0]):    \n",
    "        if arr[i - 3,close_col] > arr[i - 3,open_col] and arr[i - 2,close_col] > arr[i - 2,open_col] and arr[i - 1,close_col] > arr[i - 1,open_col] and arr[i,close_col] < arr[i - 1,open_col]: \n",
    "            arr[i,col1] = 1\n",
    "        if arr[i - 3,close_col] < arr[i - 3,open_col] and arr[i - 2,close_col] < arr[i - 2,open_col] and arr[i - 1,close_col] < arr[i - 1,open_col] and arr[i,close_col] > arr[i - 1,open_col]: \n",
    "            arr[i,col2] = 1 \n",
    "            \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def convert_timestamp(df):\n",
    "    time_col = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,time_col] = datetime.strptime(arr[i,time_col][:-4], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22):\n",
    "    print('GETTING TRADING SESSIONS')\n",
    "    print('LONDON TRADING SESSION UTC',london_start,london_end)\n",
    "    print('NEW YORK TRADING SESSION UTC',ny_start,ny_end)\n",
    "    df['new_york'] = 0\n",
    "    df['london'] = 0\n",
    "    \n",
    "    \n",
    "    col1 = df.columns.get_loc('new_york')\n",
    "    col2 = df.columns.get_loc('london')\n",
    "    utc = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i,utc].hour >= london_start and arr[i,utc].hour < london_end:\n",
    "            arr[i,col2] = 1\n",
    "        if arr[i,utc].hour >= ny_start and arr[i,utc].hour < ny_end:\n",
    "            arr[i,col1] = 1     \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def clean_and_save_data(pair = 'EUR_USD'\n",
    "                    ,granularity = 'M5'\n",
    "                    ,start = datetime(2016,1,1,0,0,0)\n",
    "                    ,end = datetime(2022,7,31,0,0,0)):\n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.shape)\n",
    "    df = smma(df,period = 21)\n",
    "    df = smma(df,period = 50)\n",
    "    df = smma(df,period = 200)\n",
    "\n",
    "    df = ema(df,num = 14 * 3)\n",
    "    df = ema(df,num = 50 * 3)\n",
    "    df = ema(df,num = 200 * 3)\n",
    "    df = engulfing_candle(df)\n",
    "    df = three_line_strike(df)\n",
    "\n",
    "\n",
    "\n",
    "    df['o'] = df['o'].astype(float)\n",
    "    df['h'] = df['h'].astype(float)\n",
    "    df['l'] = df['l'].astype(float)\n",
    "    df['c'] = df['c'].astype(float)\n",
    "\n",
    "    df = convert_timestamp(df)\n",
    "    df = get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22)\n",
    "    print('SAVING DATA AS:',path)\n",
    "    df.to_csv(path,index = False)\n",
    "    print()\n",
    "jpy_pairs=['GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY']\n",
    "major_pairs=['GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD','NZD_USD']\n",
    "cross_pairs=['AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF','EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF']\n",
    "all_pairs=['XAU_USD','GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "\n",
    "all_pairs=['GBP_JPY','EUR_USD','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "pair = 'EUR_USD'\n",
    "granularity = 'M5'\n",
    "start = datetime(2016,1,1,0,0,0)\n",
    "end = datetime(2022,7,31,0,0,0)\n",
    "\n",
    "\n",
    "for pair in all_pairs:\n",
    "    print(pair)\n",
    "    clean_and_save_data(pair = pair,granularity = granularity,start = start,end = end)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_data():\n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.shape)\n",
    "    df = smma(df,period = 21)\n",
    "    df = smma(df,period = 50)\n",
    "    df = smma(df,period = 200)\n",
    "\n",
    "    df = ema(df,num = 14 * 3)\n",
    "    df = ema(df,num = 50 * 3)\n",
    "    df = ema(df,num = 200 * 3)\n",
    "    df = engulfing_candle(df)\n",
    "    df = three_line_strike(df)\n",
    "\n",
    "\n",
    "\n",
    "    df['o'] = df['o'].astype(float)\n",
    "    df['h'] = df['h'].astype(float)\n",
    "    df['l'] = df['l'].astype(float)\n",
    "    df['c'] = df['c'].astype(float)\n",
    "\n",
    "    df = convert_timestamp(df)\n",
    "    df = get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22)\n",
    "    print('SAVING DATA AS:',path)\n",
    "    df.to_csv(path,index = False)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>volume</th>\n",
       "      <th>o</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>c</th>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th>est_timestamp</th>\n",
       "      <th>smma_21</th>\n",
       "      <th>smma_50</th>\n",
       "      <th>smma_200</th>\n",
       "      <th>ema_42</th>\n",
       "      <th>ema_150</th>\n",
       "      <th>ema_600</th>\n",
       "      <th>bearish_engulfing</th>\n",
       "      <th>bullish_engulfing</th>\n",
       "      <th>bearish_tls</th>\n",
       "      <th>bullish_tls</th>\n",
       "      <th>new_york</th>\n",
       "      <th>london</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-03T22:00:00.000000000Z</td>\n",
       "      <td>6</td>\n",
       "      <td>1.08743</td>\n",
       "      <td>1.08746</td>\n",
       "      <td>1.08724</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>2016-01-03 22:00:00+00:00</td>\n",
       "      <td>2016-01-03 17:00:00-05:00</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>1.08726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-03T22:05:00.000000000Z</td>\n",
       "      <td>53</td>\n",
       "      <td>1.08735</td>\n",
       "      <td>1.08738</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>2016-01-03 22:05:00+00:00</td>\n",
       "      <td>2016-01-03 17:05:00-05:00</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>1.0871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03T22:10:00.000000000Z</td>\n",
       "      <td>21</td>\n",
       "      <td>1.08715</td>\n",
       "      <td>1.08715</td>\n",
       "      <td>1.08674</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>2016-01-03 22:10:00+00:00</td>\n",
       "      <td>2016-01-03 17:10:00-05:00</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>1.08681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-03T22:15:00.000000000Z</td>\n",
       "      <td>19</td>\n",
       "      <td>1.08671</td>\n",
       "      <td>1.08694</td>\n",
       "      <td>1.08669</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>2016-01-03 22:15:00+00:00</td>\n",
       "      <td>2016-01-03 17:15:00-05:00</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-03T22:20:00.000000000Z</td>\n",
       "      <td>47</td>\n",
       "      <td>1.08684</td>\n",
       "      <td>1.08717</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>2016-01-03 22:20:00+00:00</td>\n",
       "      <td>2016-01-03 17:20:00-05:00</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time volume        o        h        l        c  \\\n",
       "0  2016-01-03T22:00:00.000000000Z      6  1.08743  1.08746  1.08724  1.08726   \n",
       "1  2016-01-03T22:05:00.000000000Z     53  1.08735  1.08738   1.0871   1.0871   \n",
       "2  2016-01-03T22:10:00.000000000Z     21  1.08715  1.08715  1.08674  1.08681   \n",
       "3  2016-01-03T22:15:00.000000000Z     19  1.08671  1.08694  1.08669   1.0868   \n",
       "4  2016-01-03T22:20:00.000000000Z     47  1.08684  1.08717   1.0867   1.0867   \n",
       "\n",
       "               utc_timestamp              est_timestamp  smma_21  smma_50  \\\n",
       "0  2016-01-03 22:00:00+00:00  2016-01-03 17:00:00-05:00  1.08726  1.08726   \n",
       "1  2016-01-03 22:05:00+00:00  2016-01-03 17:05:00-05:00   1.0871   1.0871   \n",
       "2  2016-01-03 22:10:00+00:00  2016-01-03 17:10:00-05:00  1.08681  1.08681   \n",
       "3  2016-01-03 22:15:00+00:00  2016-01-03 17:15:00-05:00   1.0868   1.0868   \n",
       "4  2016-01-03 22:20:00+00:00  2016-01-03 17:20:00-05:00   1.0867   1.0867   \n",
       "\n",
       "  smma_200   ema_42  ema_150  ema_600 bearish_engulfing bullish_engulfing  \\\n",
       "0  1.08726  1.08726  1.08726  1.08726                 0                 0   \n",
       "1   1.0871   1.0871   1.0871   1.0871                 0                 0   \n",
       "2  1.08681  1.08681  1.08681  1.08681                 0                 0   \n",
       "3   1.0868   1.0868   1.0868   1.0868                 0                 0   \n",
       "4   1.0867   1.0867   1.0867   1.0867                 1                 0   \n",
       "\n",
       "  bearish_tls bullish_tls  new_york  london  \n",
       "0           0           0         0       0  \n",
       "1           0           0         0       0  \n",
       "2           0           0         0       0  \n",
       "3           0           0         0       0  \n",
       "4           0           0         0       0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-01-03 22:00:00+00:00'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['utc_timestamp'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22):\n",
    "    print('GETTING TRADING SESSIONS')\n",
    "    print('LONDON TRADING SESSION UTC',london_start,london_end)\n",
    "    print('NEW YORK TRADING SESSION UTC',ny_start,ny_end)\n",
    "    df['new_york'] = 0\n",
    "    df['london'] = 0\n",
    "    \n",
    "    \n",
    "    col1 = df.columns.get_loc('new_york')\n",
    "    col2 = df.columns.get_loc('london')\n",
    "    utc = df.columns.get_loc('utc_timestamp')\n",
    "    est = df.columns.get_loc('est_timestamp')\n",
    "    arr = df.values \n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i,utc] >= london_start and arr[i,utc] < london_end:\n",
    "            arr[i,col2] = 1\n",
    "        if arr[i,utc] >= ny_start and arr[i,utc] < ny_end:\n",
    "            arr[i,col1] = 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def engulfing_candle(df):\n",
    "    print('GETTING ENGULFING CANDLES...')\n",
    "    df['bearish_engulfing'] = 0\n",
    "    df['bullish_engulfing'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_engulfing')\n",
    "    col2 = df.columns.get_loc('bullish_engulfing')\n",
    "    \n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        obp = arr[i-1,open_col] #open[1]\n",
    "        cbp = arr[i-1,close_col] #close[1]\n",
    "        obc = arr[i,open_col] #open\n",
    "        cbc = arr[i,close_col] #close        \n",
    "        #If current bar open is less than equal to the previous bar close AND current bar open is less than previous bar open AND current bar close is greater than previous bar open THEN True\n",
    "        if obc <= cbp and obc < obp and cbc > obp:\n",
    "            arr[i,col2] = 1\n",
    "        \n",
    "        #If current bar open is greater than equal to previous bar close AND current bar open is greater than previous bar open AND current bar close is less than previous bar open THEN True\n",
    "        elif obc >= cbp and obc > obp and cbc < obp:    \n",
    "            arr[i,col] = 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_line_strike(df):\n",
    "    print('GETTING 3 LINE STRIKE...')\n",
    "    df['bearish_tls'] = 0\n",
    "    df['bullish_tls'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_tls')\n",
    "    col2 = df.columns.get_loc('bullish_tls')\n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(4,arr.shape[0]):    \n",
    "        if arr[i - 3,close_col] > arr[i - 3,open_col] and arr[i - 2,close_col] > arr[i - 2,open_col] and arr[i - 1,close_col] > arr[i - 1,open_col] and arr[i,close_col] < arr[i - 1,open_col]: \n",
    "            arr[i,col1] = 1\n",
    "        if arr[i - 3,close_col] < arr[i - 3,open_col] and arr[i - 2,close_col] < arr[i - 2,open_col] and arr[i - 1,close_col] < arr[i - 1,open_col] and arr[i,close_col] > arr[i - 1,open_col]: \n",
    "            arr[i,col2] = 1   \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "!pip install plotly\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "import time\n",
    "from random import random\n",
    "pio.renderers.default = \"iframe\"\n",
    "def create_spike_trigger(df,col = 'delta_max',lookback_threshold = 3600):\n",
    "    print('CREATING SPIKE TRIGGER...')\n",
    "    df[col + '_spike_trigger'] = 0\n",
    "    col_loc = df.columns.get_loc(col)\n",
    "    arr = df.values\n",
    "    for i in range(lookback_threshold,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            cur_max = max(arr[i - lookback_threshold : i ,col_loc])\n",
    "        except:\n",
    "            print('ERROR',i)\n",
    "            cur_max = 100\n",
    "        if arr[i,col_loc] > cur_max and sum(arr[i - 100 : i,-1]) == 0:\n",
    "            arr[i,-1] = 1\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def create_wick_trigger(df,col = 'wick',lookback_threshold = 3600):\n",
    "    print('CREATING WICK TRIGGER...')\n",
    "    df['wick'] = 0\n",
    "    df.loc[df[df['delta_vector'] < 0].index,'wick'] = df.loc[df[df['delta_vector'] < 0].index,'c'] - df.loc[df[df['delta_vector'] < 0].index,'l']\n",
    "    df.loc[df[df['delta_vector'] > 0].index,'wick'] = df.loc[df[df['delta_vector'] > 0].index,'h'] - df.loc[df[df['delta_vector'] > 0].index,'c']\n",
    "    df['wick_trigger'] = 0\n",
    "\n",
    "\n",
    "    col_loc = df.columns.get_loc(col)\n",
    "    arr = df.values\n",
    "    for i in range(lookback_threshold,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            cur_max = max(arr[i - lookback_threshold : i ,col_loc])\n",
    "        except:\n",
    "            print('ERROR',i)\n",
    "            cur_max = 100\n",
    "        if arr[i,col_loc] > cur_max and sum(arr[i - 100 : i,-1]) == 0:\n",
    "            arr[i,-1] = 1\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def consecutive_candles(df,num = 10,col = 'delta_vector'):\n",
    "    print('CREATING CONSECUTIVE CANDLES TRIGGER...')\n",
    "    df[col + '_consecutive_trigger'] = 0\n",
    "    col_loc = df.columns.get_loc(col)\n",
    "    arr = df.values\n",
    "    last = -1\n",
    "    counter = 0\n",
    "    for i in range(arr.shape[0]):\n",
    "        \n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if arr[i-1,col_loc] < 0 and arr[i,col_loc] < 0:\n",
    "            counter += 1\n",
    "        elif arr[i-1,col_loc] > 0 and arr[i,col_loc] > 0:\n",
    "            counter += 1  \n",
    "        else:\n",
    "            counter = 0\n",
    "            \n",
    "        if counter == num:\n",
    "            arr[i,-1] = 1\n",
    "            counter = 0\n",
    "    df = pd.DataFrame(arr,columns = df.columns)\n",
    "    print('SHAPE OF TRIGGER DF:',df[df[col + '_consecutive_trigger'] == 1].shape)\n",
    "    return df\n",
    "\n",
    "def get_pearsons_corr(df,lookback = 10):\n",
    "    print('GETTING PEARSONS CORR')\n",
    "    df['ind'] = list(range(df.shape[0]))\n",
    "    df['pearsons_corr'] = 0\n",
    "    ind_col = df.columns.get_loc('ind')\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    \n",
    "    arr = df.values\n",
    "    for i in range(arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        r, p = sp.stats.pearsonr(arr[(i - looback) : i,ind_col], arr[(i - looback) : i,o_col])\n",
    "        arr[i,-1] = r\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def get_pearsons_corr(df,lookback = 10):\n",
    "    print('GETTING PEARSONS CORR')\n",
    "    df['ind'] = list(range(df.shape[0]))\n",
    "    df['pearsons_corr'] = 0\n",
    "    ind_col = df.columns.get_loc('ind')\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    \n",
    "    arr = df.values\n",
    "    for i in range(lookback,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        r, p = sp.stats.pearsonr(arr[(i - lookback) : i,ind_col], arr[(i - lookback) : i,o_col])\n",
    "        arr[i,-1] = r\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def get_pearsons_corr2(df,lookback = 10):\n",
    "    print('GETTING PEARSONS CORR')\n",
    "    df['ind'] = list(range(df.shape[0]))\n",
    "    df['pearsons_lookup'] = 0\n",
    "    df['pearsons_corr2'] = 0\n",
    "    ind_col = df.columns.get_loc('ind')\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    new_col = df.columns.get_loc('pearsons_lookup')\n",
    "    \n",
    "    arr = df.values\n",
    "    for i in range(lookback,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        if i % 2 == 0:\n",
    "            arr[i,new_col] = arr[i,o_col]\n",
    "        else:\n",
    "            arr[i,new_col] = arr[i,c_col]        \n",
    "            \n",
    "            \n",
    "    for i in range(lookback,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        r, p = sp.stats.pearsonr(arr[(i - lookback) : i,ind_col], arr[(i - lookback) : i,new_col])\n",
    "        arr[i,-1] = r\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def convert_timestamp(df):\n",
    "    time_col = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,time_col] = datetime.strptime(arr[i,time_col][:-4], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def get_best_fit(df,lookback = 10):\n",
    "\n",
    "    def get_slope(y1,y2,total_x = 10):\n",
    "        \"\"\"y = mx + b\"\"\"\n",
    "        return (y2 - y1) / total_x\n",
    "    def get_best_fit_vals(y1,y2,total_x = 10):\n",
    "        m = get_slope(y1,y2,total_x = total_x)\n",
    "        lst = []\n",
    "        for i in range(total_x):\n",
    "            lst.append((m * i) + y1)\n",
    "        return lst\n",
    "    def compare_vals(lst,open_list,close_list,total_x):\n",
    "\n",
    "        for i in range(total_x):\n",
    "            if lst[i] <= max(open_list[i],close_list[i]) and lst[i] >= min(open_list[i],close_list[i]):\n",
    "                pass\n",
    "            else:\n",
    "                return 0\n",
    "        return 1\n",
    "    print('GETTING BEST FIT INDICATOR')\n",
    "    df['best_fit'] = 0\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    new_col = df.columns.get_loc('best_fit')\n",
    "    \n",
    "    arr = df.values\n",
    "    total_x = lookback \n",
    "    for i in range(lookback,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        y1 = np.mean([arr[i - total_x,o_col],arr[i - total_x,c_col]])\n",
    "        y2 = np.mean([arr[i ,o_col],arr[i ,c_col]])\n",
    "        \n",
    "        temp_lst = get_best_fit_vals(y1,y2,total_x)\n",
    "        arr[i,new_col] = compare_vals(lst = temp_lst,open_list = list(arr[i - total_x:i,o_col]),close_list = list(arr[i - total_x:i,c_col]),total_x = total_x)\n",
    "            \n",
    "    \n",
    "    return pd.DataFrame(arr,columns = df.columns)   \n",
    "\n",
    "def print_example(df,ind_list,ind = 30,delta = 240,trendline_lookback = 20):\n",
    "    i = ind_list[ind]   \n",
    "    print('row loc:',i,' ind:',ind,' delta:',delta)\n",
    "    fig = go.Figure(data=go.Candlestick(x=df.iloc[i - delta:i + (delta*2),:]['time'],\n",
    "                        open=df.iloc[i - delta:i + (delta*2),:]['o'],\n",
    "                        high=df.iloc[i - delta:i + (delta*2),:]['h'],\n",
    "                        low=df.iloc[i - delta:i + (delta*2),:]['l'],\n",
    "                        close=df.iloc[i - delta:i + (delta*2),:]['c']))\n",
    "\n",
    "\n",
    "    fig.add_vrect(x0=df['time'].iloc[i - 1], x1=df['time'].iloc[i+1], \n",
    "                  annotation_text=\"trigger point\" , annotation_position=\"top left\",\n",
    "                  fillcolor=\"green\", opacity=0.25, line_width=0)\n",
    "    \n",
    "    fig.add_shape(type='line',\n",
    "                    x0=df.iloc[i - trendline_lookback,:]['time'],\n",
    "                    y0=df.iloc[i - trendline_lookback,:]['o'],\n",
    "                    x1=df.iloc[i,:]['time'],\n",
    "                    y1=df.iloc[i ,:]['o'],\n",
    "                    line=dict(color='Red',),\n",
    "                    xref='x',\n",
    "                    yref='y'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        plot(fig)\n",
    "    except:\n",
    "        from plotly.offline import plot\n",
    "        plot(fig)\n",
    "def get_max_min_open_or_close(df):\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    df['max_o_c'] = 0\n",
    "    df['min_o_c'] = 0\n",
    "    max_col = df.columns.get_loc('max_o_c')\n",
    "    min_col = df.columns.get_loc('min_o_c')    \n",
    "    arr = df.values\n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,max_col] = max(arr[i,o_col],arr[i,c_col])\n",
    "        arr[i,min_col] = min(arr[i,o_col],arr[i,c_col])\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def channel_indicator(df,lookback = 20):\n",
    "    \"\"\"Take the max of a bunch of consecutive candles and find the slope of the line\n",
    "    Take the min of a bunch of consecutive candles and find the slope of the line\n",
    "    \n",
    "    \"\"\"\n",
    "    def get_slope(y1,y2,total_x = 10):\n",
    "        \"\"\"y = mx + b\"\"\"\n",
    "        return (y2 - y1) / total_x\n",
    "    def get_best_fit_vals(y1,y2,total_x = 10):\n",
    "        m = get_slope(y1,y2,total_x = total_x)\n",
    "        lst = []\n",
    "        for i in range(total_x):\n",
    "            lst.append((m * i) + y1)\n",
    "        return lst\n",
    "    def compare_vals(lst,check_list,total_x,check_type = 'max'):\n",
    "\n",
    "        for i in range(total_x):\n",
    "            if check_type == 'max':\n",
    "                if lst[i] >= check_list[i]:\n",
    "                    pass\n",
    "                else:\n",
    "                    return 0\n",
    "            if check_type == 'min':\n",
    "                if lst[i] <= check_list[i]:\n",
    "                    pass\n",
    "                else:\n",
    "                    return 0\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "    print('GETTING CHANNEL INDICATOR')\n",
    "    df['channel_indicator'] = 0\n",
    "    max_col = df.columns.get_loc('max_o_c')\n",
    "    min_col = df.columns.get_loc('min_o_c')\n",
    "    new_col = df.columns.get_loc('channel_indicator')\n",
    "    df['spread_indicator'] = 0\n",
    "    spread_col = df.columns.get_loc('spread_indicator')\n",
    "    \n",
    "    arr = df.values\n",
    "    total_x = lookback \n",
    "    for i in range(lookback,arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "\n",
    "        y1 = arr[i - total_x,max_col]\n",
    "        y2 = arr[i ,max_col]\n",
    "        \n",
    "        temp_lst1 = get_best_fit_vals(y1,y2,total_x)\n",
    "        check_1 = compare_vals(lst = temp_lst1,\n",
    "                                      check_list = list(arr[i - total_x:i,min_col]),\n",
    "                                      total_x = total_x,\n",
    "                                      check_type = 'max'\n",
    "                                     )\n",
    "        \n",
    "        \n",
    "        y1 = arr[i - total_x,min_col]\n",
    "        y2 = arr[i ,min_col]\n",
    "        \n",
    "        temp_lst2 = get_best_fit_vals(y1,y2,total_x)\n",
    "        check_2 = compare_vals(lst = temp_lst2,\n",
    "                                      check_list = list(arr[i - total_x:i,max_col]),\n",
    "                                      total_x = total_x,\n",
    "                                      check_type = 'min'\n",
    "                                     )   \n",
    "        spread = np.array(temp_lst1) - np.array(temp_lst2)     \n",
    "        arr[i,spread_col] = max(spread)\n",
    "        \n",
    "        \n",
    "        if check_1 == 1 and check_2 == 1:\n",
    "            arr[i,new_col] = 1\n",
    "    \n",
    "    return pd.DataFrame(arr,columns = df.columns)  \n",
    "\n",
    "\n",
    "def get_support(df,lookup_range = 60,stop_range = 20000,lookup_range2 = 200):\n",
    "    print('GETTING SUPPORT INDICATOR')\n",
    "    s = time.time()\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    l_col = df.columns.get_loc('l')\n",
    "    df['support_lookup'] = 0\n",
    "    df['support_indicator'] = 0\n",
    "    lookup_col = df.columns.get_loc('support_lookup')\n",
    "    new_col = df.columns.get_loc('support_indicator')\n",
    "    arr = df.values\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        if i % 200000 == 0:\n",
    "            print(i)\n",
    "        try:\n",
    "            if arr[i,c_col] == min(arr[i - lookup_range : i + lookup_range,c_col]):\n",
    "                lookup_ind = i\n",
    "                val = arr[i,c_col]\n",
    "                lookup_check = 0\n",
    "                for j in range(i + lookup_range2,i + stop_range):\n",
    "                    if arr[j,l_col] <= val and lookup_check == 0:\n",
    "                        arr[j,new_col] = 1\n",
    "                        arr[j,lookup_col] = lookup_ind\n",
    "                        lookup_check = 1\n",
    "                        break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "    e = time.time()\n",
    "    print('TOTAL FUNCTION TIME:',(e-s)/60,' MINUTES')\n",
    "    df = pd.DataFrame(arr,columns = df.columns)\n",
    "    print('SHAPE',df[df['support_indicator'] == 1].shape)\n",
    "    return df\n",
    "\n",
    "def ema(df,num = 14):\n",
    "    print('GETTING EMA INDICATOR FOR:',num)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['ema_' + str(num)] = df['c']\n",
    "    arr = df.values\n",
    "    mult = 2/ (num + 1)\n",
    "    for i in range(num,arr.shape[0]):\n",
    "        sma = sum(arr[i - num + 1: i + 1,close_col]) / num\n",
    "        arr[i,-1] = ((arr[i,close_col] - arr[i - 1,-1]) * mult) + arr[i - 1,-1]\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "file = 'XAU_USD_M1_2019-01-01_2022-01-31.csv'\n",
    "#file = 'GBP_JPY_M1_2019-01-01_2022-01-31.csv'\n",
    "#file = 'XAU_USD_S5/2020-08-01_2020-09-01.csv'\n",
    "#file = 'GBP_JPY_S5/2020-08-01_2020-09-01.csv'\n",
    "\n",
    "file = 'EUR_USD_M1_2019-01-01_2022-01-31.csv'\n",
    "file = 'GBP_JPY_M1_2019-01-01_2022-01-31.csv'\n",
    "file = 'EUR_USD_M1_2019-01-01_2022-01-31.csv'\n",
    "file = 'GBP_JPY_M1_2019-01-01_2022-01-31.csv'\n",
    "\n",
    "file = 'EUR_USD_M1_2019-01-01_2022-01-31.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df = convert_timestamp(df)\n",
    "df = get_max_min_open_or_close(df)\n",
    "print(df.shape)\n",
    "df['o'] = df['o'].astype(float)\n",
    "df['h'] = df['h'].astype(float)\n",
    "df['l'] = df['l'].astype(float)\n",
    "df['c'] = df['c'].astype(float)\n",
    "\n",
    "df = get_support(df,lookup_range = 1500,stop_range = 20000,lookup_range2 = 200)\n",
    "\n",
    "df = ema(df,num = 14 * 15)\n",
    "\n",
    "df = ema(df,num = 50 * 15)\n",
    "df = ema(df,num = 200 * 15)\n",
    "#df = ema(df,num = 500 * 15)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
