{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oandapyV20 in /opt/anaconda3/lib/python3.8/site-packages (0.7.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install oandapyV20\n",
    "\n",
    "import oandapyV20\n",
    "from oandapyV20 import API\n",
    "import oandapyV20.endpoints.pricing as pricing\n",
    "import oandapyV20.endpoints.accounts as accounts\n",
    "import oandapyV20.endpoints.orders as orders\n",
    "import oandapyV20.endpoints.trades as trades \n",
    "import oandapyV20.endpoints.positions as positions\n",
    "import oandapyV20.endpoints.transactions as trans\n",
    "import oandapyV20.endpoints.instruments as instruments\n",
    "import oandapyV20.definitions.primitives as primitives\n",
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "import io\n",
    "from io import StringIO \n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "import time \n",
    "\n",
    "#import datedelta\n",
    "import calendar\n",
    "import  csv\n",
    "import json\n",
    "\n",
    "from oandapyV20.exceptions import V20Error\n",
    "from oandapyV20.endpoints.pricing import PricingStream\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy import stats\n",
    "def convert_to_df(instrument,granularity = \"H1\",count = 5000,percentile_test = 97,\n",
    "                  test_col = 'delta_percentile_prev_wick',positive = True,start = date(2020,1,1),end = date(2020,1,10)):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(instrument,granularity,count,percentile_test)\n",
    "    print('START:',start,' END:',end)\n",
    "    if positive:\n",
    "        negative = False\n",
    "    else:\n",
    "        negative = True\n",
    "    params = {#\"count\":count,\n",
    "              \"granularity\": granularity,\n",
    "              \"from\": str(start.isoformat('T')),\n",
    "              \"to\": str(end.isoformat('T'))\n",
    "                 }\n",
    "    print('PARAMS',params)\n",
    "    print(instrument,type(instrument))\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument,\n",
    "                                      params=params)\n",
    "    client.request(r)\n",
    "    dct = r.response\n",
    "    lst = dct['candles']\n",
    "    if len(lst) == 0:\n",
    "        print('NO RESULT RETRUNING EMPTY DF...')\n",
    "        return pd.DataFrame([0])\n",
    "    lst = []\n",
    "    i = 0\n",
    "    \n",
    "    for candle in dct['candles']:\n",
    "        #IF CANDLE IS BULLISH\n",
    "        if (float(candle['mid']['c']) - float(candle['mid']['o'])) > 0:\n",
    "            max_vector = (float(candle['mid']['h']) - float(candle['mid']['l']))\n",
    "            \n",
    "        #IF CANDLE IS BEARISH\n",
    "        else:\n",
    "            max_vector = -1 * (float(candle['mid']['h']) - float(candle['mid']['l']))\n",
    "            \n",
    "        if i == 0:\n",
    "            prev_delta = 0 \n",
    "            prev_delta_max = 0\n",
    "            prev_delta_vector = 0 \n",
    "            prev_wick = 0\n",
    "        else:\n",
    "            prev_delta = abs(float(prev_candle['mid']['c']) - float(prev_candle['mid']['o']))\n",
    "            prev_delta_max = abs(float(prev_candle['mid']['l']) - float(prev_candle['mid']['h']))\n",
    "            prev_delta_vector = (float(prev_candle['mid']['c']) - float(prev_candle['mid']['o']))\n",
    "            \n",
    "            if (float(prev_candle['mid']['c']) - float(prev_candle['mid']['o'])) > 0:\n",
    "                prev_wick = float(prev_candle['mid']['h']) - float(prev_candle['mid']['c'])\n",
    "            else:\n",
    "                prev_wick = float(prev_candle['mid']['l']) - float(prev_candle['mid']['o'])\n",
    "\n",
    "\n",
    "        lst.append([candle['time'],candle['volume'],float(candle['mid']['o']),float(candle['mid']['h']),float(candle['mid']['l']),\n",
    "                        float(candle['mid']['c']),abs(float(candle['mid']['c']) - float(candle['mid']['o'])),\n",
    "                    abs(float(candle['mid']['l']) - float(candle['mid']['h'])),\n",
    "                     (float(candle['mid']['c']) - float(candle['mid']['o'])),max_vector,\n",
    "\n",
    "                    prev_delta,prev_delta_max,prev_delta_vector,prev_wick\n",
    "\n",
    "                   ])\n",
    "        \n",
    "        prev_candle = candle\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst,columns = ['time','volume','o','h','l','c','delta','delta_max',\n",
    "                                     'delta_vector','max_vector','prev_delta',\n",
    "                                     'prev_delta_max','prev_delta_vector','prev_wick'])\n",
    "    \n",
    "    \n",
    "    df['prev_5'] = 0\n",
    "    df['prev_10'] = 0\n",
    "    df['prev_24'] = 0\n",
    "    \n",
    "    \n",
    "    df['next_candle'] = 0\n",
    "    df['next_2'] = 0\n",
    "    df['next_3'] = 0\n",
    "    df['next_4'] = 0\n",
    "    df['next_5'] = 0\n",
    "    df['next_10'] = 0\n",
    "    \n",
    "    df['next_candle+1'] = 0\n",
    "    df['next_2+1'] = 0\n",
    "    df['next_3+1'] = 0\n",
    "    df['next_4+1'] = 0\n",
    "    df['next_5+1'] = 0\n",
    "    df['next_10+1'] = 0\n",
    "    df['next_20+1'] = 0\n",
    "        \n",
    "    tot_length = df.shape[0]\n",
    "    for i in range(df.shape[0] - 21):\n",
    "        \n",
    "        df['prev_5'].iloc[i] = df['c'].iloc[i] - df['c'].iloc[i - 5] \n",
    "        df['prev_10'].iloc[i] = df['c'].iloc[i] - df['c'].iloc[i - 10] \n",
    "        df['prev_24'].iloc[i] = df['c'].iloc[i] - df['c'].iloc[i - 24]    \n",
    "        \n",
    "        df['next_candle'].iloc[i] = df['c'].iloc[i + 1] - df['c'].iloc[i]\n",
    "        df['next_2'].iloc[i] = df['c'].iloc[i + 2] - df['c'].iloc[i]\n",
    "        df['next_3'].iloc[i] = df['c'].iloc[i + 3] - df['c'].iloc[i]\n",
    "        df['next_4'].iloc[i] = df['c'].iloc[i + 4] - df['c'].iloc[i]\n",
    "        df['next_5'].iloc[i] = df['c'].iloc[i + 5] - df['c'].iloc[i]\n",
    "        df['next_10'].iloc[i] = df['c'].iloc[i + 10] - df['c'].iloc[i]\n",
    "        \n",
    "        df['next_candle+1'].iloc[i] = df['c'].iloc[i + 1+1] - df['c'].iloc[i+1]\n",
    "        df['next_2+1'].iloc[i] = df['c'].iloc[i + 2+1] - df['c'].iloc[i+1]\n",
    "        df['next_3+1'].iloc[i] = df['c'].iloc[i + 3+1] - df['c'].iloc[i+1]\n",
    "        df['next_4+1'].iloc[i] = df['c'].iloc[i + 4+1] - df['c'].iloc[i+1]\n",
    "        df['next_5+1'].iloc[i] = df['c'].iloc[i + 5+1] - df['c'].iloc[i+1]\n",
    "        df['next_10+1'].iloc[i] = df['c'].iloc[i + 10+1] - df['c'].iloc[i+1]\n",
    "        df['next_20+1'].iloc[i] = df['c'].iloc[i + 20+1] - df['c'].iloc[i+1] \n",
    "        \n",
    "        \n",
    "    col = test_col\n",
    "    filter_df = df[df[col] >= np.percentile(df[col], percentile_test)]\n",
    "    print('SHAPE',filter_df.shape)\n",
    "    df['trigger'] = 0\n",
    "\n",
    "    df.loc[df[df[col] >= np.percentile(df[col], percentile_test)].index,'trigger'] = 1    \n",
    "    \n",
    "    print('SHAPE2',df[df.trigger == 1].shape)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def convert_to_simple_df(instrument,granularity = \"H1\",count = 5000,start = date(2020,1,1),end = date(2020,1,10)):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(instrument,granularity,count)\n",
    "    print('START:',start,' END:',end)\n",
    "\n",
    "    params = {#\"count\":count,\n",
    "              \"granularity\": granularity,\n",
    "              \"from\": str(start.isoformat('T')),\n",
    "              \"to\": str(end.isoformat('T'))\n",
    "                 }\n",
    "    print('PARAMS',params)\n",
    "    print(instrument,type(instrument))\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument,\n",
    "                                      params=params)\n",
    "    client.request(r)\n",
    "    dct = r.response\n",
    "    lst = dct['candles']\n",
    "    if len(lst) == 0:\n",
    "        print('NO RESULT RETRUNING EMPTY DF...')\n",
    "        return pd.DataFrame([0])\n",
    "    lst = []\n",
    "    i = 0\n",
    "    \n",
    "    for candle in dct['candles']:\n",
    "\n",
    "        lst.append([candle['time'],\n",
    "                    candle['volume'],\n",
    "                    float(candle['mid']['o']),\n",
    "                    float(candle['mid']['h']),\n",
    "                    float(candle['mid']['l']),\n",
    "                    float(candle['mid']['c'])\n",
    "                   ])\n",
    "        \n",
    " \n",
    "        i += 1\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst,columns = ['time','volume','o','h','l','c'])\n",
    "    \n",
    "    df['utc_timestamp'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S', errors ='coerce')\n",
    "    df['est_timestamp'] = df['utc_timestamp'].dt.tz_convert('US/Eastern')        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_simple_df(instrument,granularity = \"H1\",count = 5000,start = date(2020,1,1),end = date(2020,1,10)):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(instrument,granularity,count)\n",
    "    print('START:',start,' END:',end)\n",
    "\n",
    "    params = {#\"count\":count,\n",
    "              \"granularity\": granularity,\n",
    "              \"from\": str(start.isoformat('T')),\n",
    "              \"to\": str(end.isoformat('T'))\n",
    "                 }\n",
    "    print('PARAMS',params)\n",
    "    print(instrument,type(instrument))\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument,\n",
    "                                      params=params)\n",
    "    client.request(r)\n",
    "    dct = r.response\n",
    "    lst = dct['candles']\n",
    "    return dct\n",
    "    if len(lst) == 0:\n",
    "        print('NO RESULT RETRUNING EMPTY DF...')\n",
    "        return pd.DataFrame([0])\n",
    "    lst = []\n",
    "    i = 0\n",
    "    \n",
    "    for candle in dct['candles']:\n",
    "\n",
    "        lst.append([candle['time'],\n",
    "                    candle['volume'],\n",
    "                    float(candle['mid']['o']),\n",
    "                    float(candle['mid']['h']),\n",
    "                    float(candle['mid']['l']),\n",
    "                    float(candle['mid']['c'])\n",
    "                   ])\n",
    "        \n",
    " \n",
    "        i += 1\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst,columns = ['time','volume','o','h','l','c'])\n",
    "    \n",
    "    df['utc_timestamp'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S', errors ='coerce')\n",
    "    df['est_timestamp'] = df['utc_timestamp'].dt.tz_convert('US/Eastern')        \n",
    "    return df\n",
    "\n",
    "#instrument = 'EUR_USD'\n",
    "#start = datetime.datetime(2020,1,1,0,0,0)\n",
    "#end = datetime.datetime(2020,1,2,0,0,0)\n",
    "#dct = convert_to_simple_df(instrument,granularity = \"H1\",count = 5000,start = start,end = end)\n",
    "#dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_simple_df(instrument,granularity = \"H1\",count = 5000,start = date(2020,1,1),end = date(2020,1,10)):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(instrument,granularity,count)\n",
    "    print('START:',start,' END:',end)\n",
    "\n",
    "    params = {#\"count\":count,\n",
    "              \"granularity\": granularity,\n",
    "              \"from\": str(start.isoformat('T')),\n",
    "              \"to\": str(end.isoformat('T'))\n",
    "                 }\n",
    "    print('PARAMS',params)\n",
    "    print(instrument,type(instrument))\n",
    "    r = instruments.InstrumentsCandles(instrument=instrument,\n",
    "                                      params=params)\n",
    "    client.request(r)\n",
    "    dct = r.response\n",
    "    lst = dct['candles']\n",
    "    if len(lst) == 0:\n",
    "        print('NO RESULT RETRUNING EMPTY DF...')\n",
    "        return pd.DataFrame([0])\n",
    "    lst = []\n",
    "    i = 0\n",
    "    \n",
    "    for candle in dct['candles']:\n",
    "\n",
    "        lst.append([candle['time'],\n",
    "                    candle['volume'],\n",
    "                    float(candle['mid']['o']),\n",
    "                    float(candle['mid']['h']),\n",
    "                    float(candle['mid']['l']),\n",
    "                    float(candle['mid']['c'])\n",
    "                   ])\n",
    "        \n",
    " \n",
    "        i += 1\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst,columns = ['time','volume','o','h','l','c'])\n",
    "    \n",
    "    df['utc_timestamp'] = pd.to_datetime(df['time'], format = '%Y-%m-%d %H:%M:%S', errors ='coerce')\n",
    "    df['est_timestamp'] = df['utc_timestamp'].dt.tz_convert('US/Eastern')        \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_data_and_save(instrument,start,end,pair,hours = 3,granularity = \"M1\"):\n",
    "\n",
    "    print('CREATING DATASET...')\n",
    "    s = time.time()\n",
    "    print('PARAMS:',start,end,pair,granularity)\n",
    "    cur = start\n",
    "\n",
    "    #i = 'GBP_JPY'\n",
    "    total_df = 0\n",
    "    dct = {}\n",
    "    \n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    \n",
    "    isdir = os.path.isdir(dir_name) \n",
    "    if isdir:\n",
    "        pass\n",
    "    else:\n",
    "        print('MAKING DIRECTORY:',dir_name)\n",
    "        os.mkdir(dir_name) \n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    while cur < end:\n",
    "        print(cur)    \n",
    "        df = convert_to_simple_df(instrument = instrument,granularity = granularity,count = 5000,start = cur,end = cur + timedelta(hours = hours))\n",
    "        \n",
    "\n",
    "        cur = cur + timedelta(hours = hours)\n",
    "\n",
    "        print(df.shape)\n",
    "        if df.shape[1] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total_df = total_df.append(df)\n",
    "            except:\n",
    "                total_df = df\n",
    "                \n",
    "            dct[str(cur)] = df\n",
    "\n",
    "    print(total_df.shape)\n",
    "    total_df.to_csv(path,index = False)\n",
    "    e = time.time()\n",
    "    print('TOTAL DATASET CONSTRUCTION TIME:',(e-s)/60,' MINUTES')\n",
    "accountID='101-001-20062555-002'\n",
    "access_token='2ad78612c58e604890fd961550f73cfd-28190cc09d5cbc67b2c14503575d6132'\n",
    "\n",
    "api = API(access_token)\n",
    "client=API(access_token)\n",
    "\n",
    "jpy_pairs=['GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY']\n",
    "major_pairs=['GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD','NZD_USD']\n",
    "cross_pairs=['AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF','EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF']\n",
    "all_pairs=['USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF']    \n",
    "jpy_pairs=['GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY']\n",
    "major_pairs=['GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD','NZD_USD']\n",
    "cross_pairs=['AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF','EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF']\n",
    "all_pairs=['XAU_USD','GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "\n",
    "all_pairs=['GBP_JPY','EUR_USD','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "all_pairs = ['XAU_USD']\n",
    "all_pairs=['GBP_JPY','EUR_USD','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "start = datetime.datetime(2005,1,1,0,0,0)\n",
    "end = datetime.datetime(2023,1,1,0,0,0)\n",
    "for pair in all_pairs:\n",
    "    create_data_and_save(instrument = pair,start = start,end = end,pair = pair,hours = 1000,granularity = \"H1\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBP_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1357040, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "EUR_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_USD_M5/2005-01-01_2023-01-01.csv\n",
      "(1355531, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_USD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "USD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1354231, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "EUR_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1356453, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "AUD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1356866, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "CAD_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1356954, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "CHF_JPY\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CHF_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "(1356872, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CHF_JPY_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "GBP_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_USD_M5/2005-01-01_2023-01-01.csv\n",
      "(1351347, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/GBP_USD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "USD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "(1346809, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "USD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "(1342865, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/USD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "AUD_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_USD_M5/2005-01-01_2023-01-01.csv\n",
      "(1349377, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_USD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "NZD_USD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_USD_M5/2005-01-01_2023-01-01.csv\n",
      "(1348452, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_USD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "AUD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "(1355347, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "AUD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "(1356729, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "AUD_NZD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_NZD_M5/2005-01-01_2023-01-01.csv\n",
      "(1353668, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/AUD_NZD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "CAD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "(1354767, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/CAD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "EUR_AUD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_AUD_M5/2005-01-01_2023-01-01.csv\n",
      "(1356439, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_AUD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "EUR_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "(1356842, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "EUR_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "(1343206, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/EUR_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "NZD_CAD\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "(1354351, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CAD_M5/2005-01-01_2023-01-01.csv\n",
      "\n",
      "NZD_CHF\n",
      "PATH: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "(1356281, 8)\n",
      "GETTING SMMA INDICATOR FOR: 21\n",
      "GETTING SMMA INDICATOR FOR: 50\n",
      "GETTING SMMA INDICATOR FOR: 200\n",
      "GETTING EMA INDICATOR FOR: 42\n",
      "GETTING EMA INDICATOR FOR: 150\n",
      "GETTING EMA INDICATOR FOR: 600\n",
      "GETTING ENGULFING CANDLES...\n",
      "GETTING 3 LINE STRIKE...\n",
      "GETTING TRADING SESSIONS\n",
      "LONDON TRADING SESSION UTC 7 16\n",
      "NEW YORK TRADING SESSION UTC 13 22\n",
      "SAVING DATA AS: /Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/NZD_CHF_M5/2005-01-01_2023-01-01.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "def create_data_and_save(instrument,start,end,pair,hours = 3,granularity = \"M1\"):\n",
    "\n",
    "    print('CREATING DATASET...')\n",
    "    s = time.time()\n",
    "    print('PARAMS:',start,end,pair,granularity)\n",
    "    cur = start\n",
    "\n",
    "    #i = 'GBP_JPY'\n",
    "    total_df = 0\n",
    "    dct = {}\n",
    "    \n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    \n",
    "    isdir = os.path.isdir(dir_name) \n",
    "    if isdir:\n",
    "        pass\n",
    "    else:\n",
    "        print('MAKING DIRECTORY:',dir_name)\n",
    "        os.mkdir(dir_name) \n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    while cur < end:\n",
    "        print(cur)    \n",
    "        df = convert_to_simple_df(instrument = instrument,granularity = granularity,count = 5000,start = cur,end = cur + timedelta(hours = hours))\n",
    "        \n",
    "\n",
    "        cur = cur + timedelta(hours = hours)\n",
    "\n",
    "        print(df.shape)\n",
    "        if df.shape[1] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                total_df = total_df.append(df)\n",
    "            except:\n",
    "                total_df = df\n",
    "                \n",
    "            dct[str(cur)] = df\n",
    "\n",
    "    print(total_df.shape)\n",
    "    total_df.to_csv(path,index = False)\n",
    "    e = time.time()\n",
    "    print('TOTAL DATASET CONSTRUCTION TIME:',(e-s)/60,' MINUTES')\n",
    "    \n",
    "    \n",
    "def smma(df,period = 14):\n",
    "    print('GETTING SMMA INDICATOR FOR:',period)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['smma_' + str(period)] = df['c']\n",
    "    smma_col = df.columns.get_loc('smma_' + str(period))\n",
    "    arr = df.values\n",
    "    \n",
    "    #SMMA CALC:\n",
    "    \n",
    "    #SUM1=SUM (CLOSE, N)\n",
    "\n",
    "    #SMMA1 = SUM1/ N\n",
    "\n",
    "    #The second and subsequent moving averages are calculated according to this formula:\n",
    "\n",
    "    #SMMA (i) = (SUM1 – SMMA1+CLOSE (i))/ N    \n",
    "    \n",
    "   # Where:\n",
    "\n",
    "    #SUM1 – is the total sum of closing prices for N periods;\n",
    "    #SMMA1 – is the smoothed moving average of the first bar;\n",
    "    #SMMA (i) – is the smoothed moving average of the current bar (except the first one);\n",
    "    #CLOSE (i) – is the current closing price;\n",
    "    #N – is the smoothing period.    \n",
    "\n",
    "    for i in range(period,arr.shape[0]):\n",
    "        if i == period:\n",
    "            sum1 = sum(arr[:i,close_col])\n",
    "\n",
    "            smma1 = sum1 / period\n",
    " \n",
    "            arr[i,smma_col] = smma1\n",
    "        elif i == period + 1:\n",
    "            arr[i,smma_col] = (smma1 * (period - 1) + arr[i,close_col]) / period\n",
    "            \n",
    "        else:\n",
    "\n",
    "            prev_sum = arr[i - 1,smma_col] * period\n",
    "            arr[i,smma_col] = (prev_sum - arr[i - 1,smma_col] + arr[i,close_col]) / period\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def ema(df,num = 14):\n",
    "    print('GETTING EMA INDICATOR FOR:',num)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['ema_' + str(num)] = df['c']\n",
    "    arr = df.values\n",
    "    mult = 2/ (num + 1)\n",
    "    for i in range(num,arr.shape[0]):\n",
    "        sma = sum(arr[i - num + 1: i + 1,close_col]) / num\n",
    "        arr[i,-1] = ((arr[i,close_col] - arr[i - 1,-1]) * mult) + arr[i - 1,-1]\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def engulfing_candle(df):\n",
    "    print('GETTING ENGULFING CANDLES...')\n",
    "    df['bearish_engulfing'] = 0\n",
    "    df['bullish_engulfing'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_engulfing')\n",
    "    col2 = df.columns.get_loc('bullish_engulfing')\n",
    "    \n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        obp = arr[i-1,open_col] #open[1]\n",
    "        cbp = arr[i-1,close_col] #close[1]\n",
    "        obc = arr[i,open_col] #open\n",
    "        cbc = arr[i,close_col] #close        \n",
    "        #If current bar open is less than equal to the previous bar close AND current bar open is less than previous bar open AND current bar close is greater than previous bar open THEN True\n",
    "        if obc <= cbp and obc < obp and cbc > obp:\n",
    "            arr[i,col2] = 1\n",
    "        \n",
    "        #If current bar open is greater than equal to previous bar close AND current bar open is greater than previous bar open AND current bar close is less than previous bar open THEN True\n",
    "        elif obc >= cbp and obc > obp and cbc < obp:    \n",
    "            arr[i,col1] = 1\n",
    "        \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "\n",
    "def three_line_strike(df):\n",
    "    print('GETTING 3 LINE STRIKE...')\n",
    "    df['bearish_tls'] = 0\n",
    "    df['bullish_tls'] = 0\n",
    "    col1 = df.columns.get_loc('bearish_tls')\n",
    "    col2 = df.columns.get_loc('bullish_tls')\n",
    "    open_col = df.columns.get_loc('o')\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    arr = df.values \n",
    "    for i in range(4,arr.shape[0]):    \n",
    "        if arr[i - 3,close_col] > arr[i - 3,open_col] and arr[i - 2,close_col] > arr[i - 2,open_col] and arr[i - 1,close_col] > arr[i - 1,open_col] and arr[i,close_col] < arr[i - 1,open_col]: \n",
    "            arr[i,col1] = 1\n",
    "        if arr[i - 3,close_col] < arr[i - 3,open_col] and arr[i - 2,close_col] < arr[i - 2,open_col] and arr[i - 1,close_col] < arr[i - 1,open_col] and arr[i,close_col] > arr[i - 1,open_col]: \n",
    "            arr[i,col2] = 1 \n",
    "            \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def convert_timestamp(df):\n",
    "    time_col = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,time_col] = datetime.strptime(arr[i,time_col][:-4], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22):\n",
    "    print('GETTING TRADING SESSIONS')\n",
    "    print('LONDON TRADING SESSION UTC',london_start,london_end)\n",
    "    print('NEW YORK TRADING SESSION UTC',ny_start,ny_end)\n",
    "    df['new_york'] = 0\n",
    "    df['london'] = 0\n",
    "    \n",
    "    \n",
    "    col1 = df.columns.get_loc('new_york')\n",
    "    col2 = df.columns.get_loc('london')\n",
    "    utc = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i,utc].hour >= london_start and arr[i,utc].hour < london_end:\n",
    "            arr[i,col2] = 1\n",
    "        if arr[i,utc].hour >= ny_start and arr[i,utc].hour < ny_end:\n",
    "            arr[i,col1] = 1     \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "def clean_and_save_data(pair = 'EUR_USD'\n",
    "                    ,granularity = 'M5'\n",
    "                    ,start = datetime(2016,1,1,0,0,0)\n",
    "                    ,end = datetime(2022,7,31,0,0,0)):\n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    df = pd.read_csv(path)\n",
    "    print(df.shape)\n",
    "    df = smma(df,period = 21)\n",
    "    df = smma(df,period = 50)\n",
    "    df = smma(df,period = 200)\n",
    "\n",
    "    df = ema(df,num = 14 * 3)\n",
    "    df = ema(df,num = 50 * 3)\n",
    "    df = ema(df,num = 200 * 3)\n",
    "    df = engulfing_candle(df)\n",
    "    df = three_line_strike(df)\n",
    "\n",
    "\n",
    "\n",
    "    df['o'] = df['o'].astype(float)\n",
    "    df['h'] = df['h'].astype(float)\n",
    "    df['l'] = df['l'].astype(float)\n",
    "    df['c'] = df['c'].astype(float)\n",
    "\n",
    "    df = convert_timestamp(df)\n",
    "    df = get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22)\n",
    "    print('SAVING DATA AS:',path)\n",
    "    df.to_csv(path,index = False)\n",
    "    print()\n",
    "jpy_pairs=['GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY']\n",
    "major_pairs=['GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD','NZD_USD']\n",
    "cross_pairs=['AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF','EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF']\n",
    "all_pairs=['XAU_USD','GBP_JPY','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','EUR_USD','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "\n",
    "all_pairs=['GBP_JPY','EUR_USD','USD_JPY','EUR_JPY','AUD_JPY','CAD_JPY','CHF_JPY',\n",
    "           'GBP_USD','USD_CAD','USD_CHF','AUD_USD',\n",
    "           'NZD_USD','AUD_CAD','AUD_CHF','AUD_NZD','CAD_CHF',\n",
    "           'EUR_AUD','EUR_CAD','EUR_CHF','NZD_CAD','NZD_CHF'] \n",
    "\n",
    "granularity = 'M5'\n",
    "start = datetime(2005,1,1,0,0,0)\n",
    "end = datetime(2023,1,1,0,0,0)\n",
    "\n",
    "\n",
    "for pair in all_pairs:\n",
    "    print(pair)\n",
    "    clean_and_save_data(pair = pair,granularity = granularity,start = start,end = end)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp(df):\n",
    "    time_col = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,time_col] = datetime.strptime(arr[i,time_col][:-4], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "df = convert_timestamp(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smma(df,period = 14):\n",
    "    print('GETTING SMMA INDICATOR FOR:',period)\n",
    "    close_col = df.columns.get_loc('c')\n",
    "    df['smma_' + str(period)] = df['c']\n",
    "    smma_col = df.columns.get_loc('smma_' + str(period))\n",
    "    arr = df.values\n",
    "    \n",
    "    #SMMA CALC:\n",
    "    \n",
    "    #SUM1=SUM (CLOSE, N)\n",
    "\n",
    "    #SMMA1 = SUM1/ N\n",
    "\n",
    "    #The second and subsequent moving averages are calculated according to this formula:\n",
    "\n",
    "    #SMMA (i) = (SUM1 – SMMA1+CLOSE (i))/ N    \n",
    "    \n",
    "   # Where:\n",
    "\n",
    "    #SUM1 – is the total sum of closing prices for N periods;\n",
    "    #SMMA1 – is the smoothed moving average of the first bar;\n",
    "    #SMMA (i) – is the smoothed moving average of the current bar (except the first one);\n",
    "    #CLOSE (i) – is the current closing price;\n",
    "    #N – is the smoothing period.    \n",
    "\n",
    "    for i in range(period,arr.shape[0]):\n",
    "        if i == period:\n",
    "            sum1 = sum(arr[:i,close_col])\n",
    "\n",
    "            smma1 = sum1 / period\n",
    " \n",
    "            arr[i,smma_col] = smma1\n",
    "        elif i == period + 1:\n",
    "            arr[i,smma_col] = (smma1 * (period - 1) + arr[i,close_col]) / period\n",
    "            \n",
    "        else:\n",
    "\n",
    "            prev_sum = arr[i - 1,smma_col] * period\n",
    "            arr[i,smma_col] = (prev_sum - arr[i - 1,smma_col] + arr[i,close_col]) / period\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "\n",
    "def get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22):\n",
    "    print('GETTING TRADING SESSIONS')\n",
    "    print('LONDON TRADING SESSION UTC',london_start,london_end)\n",
    "    print('NEW YORK TRADING SESSION UTC',ny_start,ny_end)\n",
    "    df['new_york'] = 0\n",
    "    df['london'] = 0\n",
    "    \n",
    "    \n",
    "    col1 = df.columns.get_loc('new_york')\n",
    "    col2 = df.columns.get_loc('london')\n",
    "    utc = df.columns.get_loc('time')\n",
    "    arr = df.values \n",
    "\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i,utc].hour >= london_start and arr[i,utc].hour < london_end:\n",
    "            arr[i,col2] = 1\n",
    "        if arr[i,utc].hour >= ny_start and arr[i,utc].hour < ny_end:\n",
    "            arr[i,col1] = 1     \n",
    "    return pd.DataFrame(arr,columns = df.columns)\n",
    "    df = smma(df,period = 21)\n",
    "    df = smma(df,period = 50)\n",
    "    df = smma(df,period = 200)\n",
    "df = get_trading_session(df,london_start = 7,london_end = 16,ny_start = 13,ny_end = 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
