{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from datetime import datetime\n",
    "import scipy as sp\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import io\n",
    "from io import StringIO \n",
    "#import datedelta\n",
    "import calendar\n",
    "import  csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def add_delta_cols(df):\n",
    "    #df['delta_vector'] = 0\n",
    "    #df['delta_max_vector'] = 0\n",
    "\n",
    "    df['delta_vector'] = 0\n",
    "    df['delta_max'] = 0\n",
    "    df['upper_wick'] = 0\n",
    "    df['lower_wick'] = 0\n",
    "    \n",
    "    dv_col = df.columns.get_loc('delta_vector')\n",
    "    dm_col = df.columns.get_loc('delta_max')\n",
    "    uw_col = df.columns.get_loc('upper_wick')\n",
    "    lw_col = df.columns.get_loc('lower_wick')\n",
    "    \n",
    "    o_col = df.columns.get_loc('o')\n",
    "    h_col = df.columns.get_loc('h')\n",
    "    l_col = df.columns.get_loc('l')\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    arr = df.values\n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i,dv_col] = arr[i,c_col] - arr[i,o_col]\n",
    "        arr[i,dm_col] = arr[i,h_col] - arr[i,l_col]\n",
    "        if arr[i,c_col] > arr[i,o_col]:\n",
    "            arr[i,uw_col] = arr[i,h_col] - arr[i,c_col]\n",
    "            arr[i,lw_col] = arr[i,o_col] - arr[i,l_col]\n",
    "            \n",
    "        elif arr[i,c_col] < arr[i,o_col]:\n",
    "            arr[i,uw_col] = arr[i,h_col] - arr[i,o_col]\n",
    "            arr[i,lw_col] = arr[i,c_col] - arr[i,l_col]   \n",
    "            \n",
    "    df = pd.DataFrame(arr,columns = df.columns)\n",
    "    df['delta'] = abs(df['delta_vector'])\n",
    "    \n",
    "    return df\n",
    "def load_df(pair = 'EUR_USD'\n",
    "            ,granularity = 'M5'\n",
    "            ,start = datetime(2016,1,1,0,0,0)\n",
    "            ,end = datetime(2022,7,31,0,0,0)):\n",
    "    def convert_timestamp(df):\n",
    "        time_col = df.columns.get_loc('time')\n",
    "        df['minute_col'] = 0\n",
    "        df['hour_col'] = 0\n",
    "        new_col = df.columns.get_loc('minute_col')\n",
    "        new_col2 = df.columns.get_loc('hour_col')\n",
    "        arr = df.values \n",
    "        for i in range(arr.shape[0]):\n",
    "            arr[i,new_col] = pd.Timestamp(arr[i,time_col]).minute\n",
    "            arr[i,new_col2] = pd.Timestamp(arr[i,time_col]).hour\n",
    "        return pd.DataFrame(arr,columns = df.columns)\n",
    "    dir_name = os.getcwd() + '/' + pair + '_' + granularity\n",
    "    path = dir_name + '/' + str(date(start.year,start.month,start.day)) + '_' + str(date(end.year,end.month,end.day)) + '.csv'\n",
    "    print('PATH:',path)\n",
    "    df = pd.read_csv(path)\n",
    "    df = add_delta_cols(df)\n",
    "    df = convert_timestamp(df)\n",
    "    df = df.drop_duplicates(subset=['utc_timestamp'])\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_support(df,\n",
    "                df2,\n",
    "                lookup_range = 1500,\n",
    "                pip_delta = .001,\n",
    "                time_range = 11,\n",
    "                high_spread = .0005,\n",
    "                low_spread = 0,\n",
    "                percentile = 98\n",
    "               ):\n",
    "    print('GETTING SUPPORT INDICATOR')\n",
    "    print('LOOKUP RANGE AND PIP DELTA:',lookup_range,pip_delta)\n",
    "    s = time.time()\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    o_col = df.columns.get_loc('o')\n",
    "    l_col = df.columns.get_loc('l')\n",
    "    h_col = df.columns.get_loc('h')\n",
    "    d_col = df.columns.get_loc('delta')\n",
    "    minute_col = df.columns.get_loc('minute_col')\n",
    "    df['support_indicator'] = 0\n",
    "    new_col = df.columns.get_loc('support_indicator')\n",
    "    arr = df.values\n",
    "    min_count = 0\n",
    "    c = 0 \n",
    "   # high_spread = .0003\n",
    "    #low_spread = .0001\n",
    "    #low_spread = 0\n",
    "    #high_spread = .0005\n",
    "    min_filter = np.percentile(df2['delta'],percentile)\n",
    "    \n",
    "    for i in range(max(lookup_range,time_range + 1),arr.shape[0]):\n",
    "       # try:\n",
    "        #DEFINE SUPPORT/RESISTANCE as the MIN or MAX of a lookup range\n",
    "\n",
    "        if (arr[i - time_range,o_col] - arr[i,c_col]) >= min_filter and arr[i,minute_col] == 55 and sum(arr[i - 50: i,new_col]) == 0:\n",
    "            arr[i,new_col] = 1\n",
    "\n",
    "    print('COUNT:',c)\n",
    "\n",
    "    e = time.time()\n",
    "    print('TOTAL FUNCTION TIME:',(e-s)/60,' MINUTES')\n",
    "    df = pd.DataFrame(arr,columns = df.columns)\n",
    "    print('SUPPORT INDICATOR SHAPE',df[df['support_indicator'] == 1].shape)\n",
    "    return df\n",
    "def test_future(df,pair,column = 'support_indicator'):\n",
    "    if 'JPY' in pair:\n",
    "        mult = 100\n",
    "    else:\n",
    "        mult = 100 * 100\n",
    "    c_col = df.columns.get_loc('c')\n",
    "    col = df.columns.get_loc(column)\n",
    "    \n",
    "    lst = []\n",
    "    arr = df.values\n",
    "    for i in range(arr.shape[0] - 101):\n",
    "        if arr[i,col] == 1:\n",
    "            c = arr[i,c_col]\n",
    "\n",
    "            lst.append([mult * (arr[i + 6,c_col] - c),\n",
    "                        mult * (arr[i + 12,c_col] - c),\n",
    "                        mult * (arr[i + 24,c_col] - c),\n",
    "                        mult * (arr[i + 48,c_col] - c),\n",
    "                        mult * (arr[i + 100,c_col] - c)                       \n",
    "                       ])\n",
    "    df2 = pd.DataFrame(lst,columns = ['next_30','next_hour','next_two_hours','next_four_hours','next_eight_hours'])  \n",
    "    print('MEDIAN:')\n",
    "    print(df2.median())\n",
    "    print()\n",
    "    print('MEAN:')\n",
    "    print(df2.mean())\n",
    "    print()\n",
    "    print('SUM:')\n",
    "    print(print(pd.DataFrame(df2.sum()).T))\n",
    "    \n",
    "    return pd.DataFrame(df2.median(),columns = [pair]).T,pd.DataFrame(df2.mean(),columns = [pair]).T,pd.DataFrame(df2.sum(),columns = [pair]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, roc_auc_score, roc_curve,recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 314159265\n",
    "VALID_SIZE = 0.2\n",
    "TARGET = 'outcome'\n",
    "def save_xgb_model(model,params,auc_score,auc_score2):\n",
    "    print('SAVING XGB MODEL')\n",
    "    import json\n",
    "    project_folder = 'risk_ml_model'\n",
    "    prefix = os.getcwd() + '/ML_MODEL_V1/AUC_train_' + str(round(auc_score2 * 100,2)) + '_AUC_test_' + str(round(auc_score * 100,2))\n",
    "    print('saving xgb model:',prefix)\n",
    "    directory = prefix\n",
    "    isdir = os.path.isdir(directory) \n",
    "    if isdir:\n",
    "        print('DIRECTORY:',directory,' EXISTS, passing...')\n",
    "        pass\n",
    "    else:\n",
    "        print('MAKING DIRECTORY:',directory)\n",
    "        os.mkdir(directory) \n",
    "    file_name = prefix + '/xgb.pkl'\n",
    "\n",
    "    # save\n",
    "    pickle.dump(model, open(file_name, \"wb\"))\n",
    "    \n",
    "\n",
    "    \n",
    "    # open file for writing\n",
    "    f = open(prefix + '/params.json',\"w\")\n",
    "\n",
    "    # write file\n",
    "    f.write( str(params) )\n",
    "\n",
    "    # close file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    \n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_types=feature_types)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, feature_types=feature_types)\n",
    "    \n",
    "    \n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm_model = xgb.train(params, dtrain, num_round, evals=watchlist, verbose_eval=True)\n",
    "    predictions = gbm_model.predict(dvalid,\n",
    "                                    ntree_limit=gbm_model.best_iteration + 1)\n",
    "    score = roc_auc_score(y_valid, predictions)    \n",
    "    # Predictions for validation and train sets\n",
    "    y_pred_valid = gbm_model.predict(dvalid, ntree_limit=gbm_model.best_iteration + 1)\n",
    "    y_pred_train = gbm_model.predict(dtrain, ntree_limit=gbm_model.best_iteration + 1)\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    cm_valid = confusion_matrix(y_valid, np.round(y_pred_valid))\n",
    "    f1_valid = f1_score(y_valid, np.round(y_pred_valid))\n",
    "    precision_valid = precision_score(y_valid, np.round(y_pred_valid))\n",
    "    recall_valid = recall_score(y_valid, np.round(y_pred_valid))\n",
    "    accuracy_valid = accuracy_score(y_valid, np.round(y_pred_valid))\n",
    "    auc_valid = roc_auc_score(y_valid, y_pred_valid)\n",
    "    \n",
    "    # Calculate metrics for train set\n",
    "    cm_train = confusion_matrix(y_train, np.round(y_pred_train))\n",
    "    f1_train = f1_score(y_train, np.round(y_pred_train))\n",
    "    precision_train = precision_score(y_train, np.round(y_pred_train))\n",
    "    recall_train = recall_score(y_train, np.round(y_pred_train))\n",
    "    accuracy_train = accuracy_score(y_train, np.round(y_pred_train))\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nValidation set metrics:\")\n",
    "    print(f\"Confusion matrix:\\n{cm_valid}\")\n",
    "    print(f\"F1 score: {f1_valid}\")\n",
    "    print(f\"Precision: {precision_valid}\")\n",
    "    print(f\"Recall: {recall_valid}\")\n",
    "    print(f\"Accuracy: {accuracy_valid}\")\n",
    "    print(f\"AUC score: {auc_valid}\")\n",
    "    \n",
    "    print(\"\\nTrain set metrics:\")\n",
    "    print(f\"Confusion matrix:\\n{cm_train}\")\n",
    "    print(f\"F1 score: {f1_train}\")\n",
    "    print(f\"Precision: {precision_train}\")\n",
    "    print(f\"Recall: {recall_train}\")\n",
    "    print(f\"Accuracy: {accuracy_train}\")\n",
    "    print(f\"AUC score: {auc_train}\")\n",
    "\n",
    "    # Plot AUC chart for both validation and train sets\n",
    "    fpr_valid, tpr_valid, _ = roc_curve(y_valid, y_pred_valid)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_train)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr_valid, tpr_valid, label=f'Validation AUC = {auc_valid:.2f}')\n",
    "    plt.plot(fpr_train, tpr_train, label=f'Train AUC = {auc_train:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plot_importance(gbm_model, title='Feature importances', xlabel='F score', ylabel='Features', importance_type='weight')\n",
    "    #plt.show()\n",
    "\n",
    "   # save_xgb_model(model=gbm_model, params=params, auc_score=auc_valid)\n",
    "    save_xgb_model(model = gbm_model,params = params,auc_score = score,auc_score2 = auc_train)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(\n",
    "             trials, \n",
    "             random_state=SEED):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of \n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # To learn more about XGBoost parameters, head to this page: \n",
    "    # https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 50, 250, 1),\n",
    "         #'n_estimators': 10,\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        # A problem with max_depth casted to float instead of int with\n",
    "        # the hp.quniform method.\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic',\n",
    "        # Increase this number if you have more cores. Otherwise, remove it and it will default \n",
    "        # to the maxium number. \n",
    "        'nthread': 4,\n",
    "        'booster': 'gbtree',\n",
    "        #'tree_method': 'exact',\n",
    "        'tree_method': 'hist',\n",
    "        'silent': 1,\n",
    "        'seed': random_state\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                max_evals=5, trials=trials)\n",
    "    return best\n",
    "def load_train_and_test_data(start,end,sl,tp,bullish,spread):\n",
    "\n",
    "\n",
    "    file = 'forex_ml_training_data_' + str(start.date()) + '_' + str(end.date()) + '_TP_' + str(tp) + '_SL_' + str(sl) + '_BULLISH_' + str(bullish) + '_SPREAD_' + str(spread) + '.csv'\n",
    "    file2 = 'forex_ml_validation_data_' + str(start.date()) + '_' + str(end.date()) + '_TP_' + str(tp) + '_SL_' + str(sl) + '_BULLISH_' + str(bullish) + '_SPREAD_' + str(spread) + '.csv'\n",
    "    file3 = 'forex_ml_testing_data_' + str(start.date()) + '_' + str(end.date()) + '_TP_' + str(tp) + '_SL_' + str(sl) + '_BULLISH_' + str(bullish) + '_SPREAD_' + str(spread) + '.csv'\n",
    "    \n",
    "    \n",
    "    cols = ['pair','bearish_engulfing', 'bullish_engulfing', 'bearish_tls', 'bullish_tls',\n",
    "           'previous_hour_volume', 'previous_4_hour_volume',\n",
    "           'previous_bullish_hour', 'previous_bullish_4hour',\n",
    "           'previous_bullish_8hour', 'previous_bullish_24hour',\n",
    "           'previous_bullish_50hour', 'previous_bullish_120hour',\n",
    "           'previous_bullish_250hour', 'previous_bullish_400hour',\n",
    "           'previous_delta_hour', 'previous_delta_4hour', 'previous_delta_8hour',\n",
    "           'previous_delta_24hour', 'previous_delta_50hour',\n",
    "           'previous_delta_120hour', 'previous_delta_250hour',\n",
    "           'previous_delta_400hour', 'previous_lower_wick_hour',\n",
    "           'previous_upper_wick_hour', 'low_at_low_of_last_day',\n",
    "           'low_at_low_of_last_5day', 'low_at_low_of_last_10day',\n",
    "           'low_at_low_of_last_20day', 'high_at_high_of_last_day',\n",
    "           'high_at_high_of_last_5day', 'high_at_high_of_last_10day',\n",
    "           'high_at_high_of_last_20day',\n",
    "           'close_difference_from_low_close_of_last_day',\n",
    "           'close_difference_from_low_close_of_last_5day',\n",
    "           'close_difference_from_low_close_of_last_10day',\n",
    "           'close_difference_from_high_close_of_last_day',\n",
    "           'close_difference_from_high_close_of_last_5day',\n",
    "           'close_difference_from_high_close_of_last_10day', 'hour_0_3',\n",
    "           'hour_4_7', 'hour_8_11', 'hour_12_15', 'hour_16_19', 'hour_20_23',\n",
    "           'previous_5_min_volume', 'previous_15_min_volume', 'bullish_ema_5min',\n",
    "           'bearish_ema_5min', 'previous_bullish_5min', 'previous_delta_5min',\n",
    "           'bearish_engulfing5', 'bullish_engulfing5', 'bearish_tls5']\n",
    "\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X = X[cols]\n",
    "    y = df['target']\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(X_train.shape,X_valid.shape)\n",
    "\n",
    "\n",
    "    df = pd.read_csv(file2)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    df.head()\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X_test = X[cols]\n",
    "    y_test = df['target']\n",
    "    \n",
    "    \n",
    "\n",
    "    print(X_train.shape,X_test.shape)\n",
    "\n",
    "    df = pd.read_csv(file3)\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    print(df.shape)\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X_test2 = X[cols]\n",
    "    y_test2 = df['target']    \n",
    "    \n",
    "    \n",
    "    X_train = pd.concat([X_train,X_test.iloc[:250000,:]])\n",
    "    y_train = pd.concat([y_train,y_test.iloc[:250000]])\n",
    "    X_test = X_test.iloc[250000:,:]\n",
    "    y_test = y_test.iloc[250000:]\n",
    "    \n",
    "    print('SHAPES:',X_train.shape, X_valid.shape,X_test.shape, X_test2.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid,X_test, X_test2, y_test, y_test2\n",
    "\n",
    "\n",
    "def get_feature_types(df):\n",
    "    feature_types = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.integer):\n",
    "            feature_types.append('int')\n",
    "        elif np.issubdtype(df[col].dtype, np.floating):\n",
    "            feature_types.append('float')\n",
    "        elif df[col].dtype == 'object':\n",
    "            feature_types.append('c')\n",
    "        else:\n",
    "            feature_types.append('unknown')\n",
    "    return feature_types\n",
    "\n",
    "start = datetime(2005,1,1,0,0,0)\n",
    "end = datetime(2023,1,1,0,0,0)\n",
    "\n",
    "\n",
    "sl = 5\n",
    "tp = 100\n",
    "bullish = True\n",
    "spread = .5\n",
    "\n",
    "X_train, X_valid, y_train, y_valid,X_test, X_test2, y_test, y_test2 = load_train_and_test_data(start,end,sl,tp,bullish,spread)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "feature_types = get_feature_types(X_train)\n",
    "col = 'pair'\n",
    "encoder.fit(X_train[col])\n",
    "X_train[col] = encoder.transform(X_train[col])\n",
    "X_valid[col] = encoder.transform(X_valid[col])\n",
    "X_test[col] = encoder.transform(X_test[col])\n",
    "X_test2[col] = encoder.transform(X_test2[col])\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.0.0-py3-none-macosx_10_15_x86_64.macosx_11_6_x86_64.macosx_12_5_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.10.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final balance                                                                        \n",
      "10000000                                                                             \n",
      "threshold                                                                            \n",
      "0.65                                                                                 \n",
      "RUNNING SIM ON TEST SET                                                              \n",
      "final balance                                                                        \n",
      "41055                                                                                \n",
      "threshold                                                                            \n",
      "0.65                                                                                 \n",
      "RUNNING SIM ON VALID SET                                                             \n",
      "final balance                                                                        \n",
      "18341                                                                                \n",
      "threshold                                                                            \n",
      "0.65                                                                                 \n",
      "RUNNING SIM ON 2022 SET                                                              \n",
      "final balance                                                                        \n",
      "8468                                                                                 \n",
      "threshold                                                                            \n",
      "0.65                                                                                 \n",
      "SAVING XGB MODEL                                                                     \n",
      "saving xgb model:                                                                    \n",
      "/Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/ML_MODEL_REGULARIZE5_BULLISH_True_TP_100_SL_10/AUC_train_70.59_AUC_test_70.74_SIM_BALANCE_TRAIN_10000000_VALID_18341_TEST_41055_2022_8468_threshold_0.65\n",
      "MAKING DIRECTORY:                                                                    \n",
      "/Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/ML_MODEL_REGULARIZE5_BULLISH_True_TP_100_SL_10/AUC_train_70.59_AUC_test_70.74_SIM_BALANCE_TRAIN_10000000_VALID_18341_TEST_41055_2022_8468_threshold_0.65\n",
      "\tScore 0.6892718576972504                                                            \n",
      "\n",
      "\n",
      "Training with params:                                                                 \n",
      "{'booster': 'gbtree', 'colsample_bytree': 0.6000000000000001, 'eta': 0.35000000000000003, 'eval_metric': 'auc', 'gamma': 0.6000000000000001, 'max_depth': 5, 'min_child_weight': 6.0, 'n_estimators': 125.0, 'nthread': 4, 'objective': 'binary:logistic', 'scale_pos_weight': 19.895773824806323, 'seed': 314159265, 'silent': 1, 'subsample': 0.5, 'tree_method': 'hist'}\n",
      "[17:01:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\teval-auc:0.66391\ttrain-auc:0.65422                                                \n",
      "[1]\teval-auc:0.67646\ttrain-auc:0.66694                                                \n",
      "[2]\teval-auc:0.68149\ttrain-auc:0.67256                                                \n",
      "[3]\teval-auc:0.68721\ttrain-auc:0.67786                                                \n",
      "[4]\teval-auc:0.68851\ttrain-auc:0.67974                                                \n",
      "[5]\teval-auc:0.68914\ttrain-auc:0.68100                                                \n",
      "[6]\teval-auc:0.69132\ttrain-auc:0.68296                                                \n",
      "[7]\teval-auc:0.69264\ttrain-auc:0.68450                                                \n",
      "[8]\teval-auc:0.69320\ttrain-auc:0.68565                                                \n",
      "[9]\teval-auc:0.69338\ttrain-auc:0.68636                                                \n",
      "[10]\teval-auc:0.69415\ttrain-auc:0.68723                                               \n",
      " 10%|█         | 10/100 [37:35<5:45:51, 230.57s/trial, best loss: 0.23698800697476496]"
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "                        \n",
    "def print_results(gbm_model,dvalid,y_valid,label,threshold = 0.65):\n",
    "    predictions_prob = gbm_model.predict(dvalid)\n",
    "\n",
    "    # Set a threshold for classifying examples into the positive class\n",
    "    \n",
    "    predictions = (predictions_prob > threshold).astype(int)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    cm = confusion_matrix(y_valid, predictions)\n",
    "    num_trades = int(cm[1][1] + cm[0][1])\n",
    "    if num_trades == 0:\n",
    "        pass\n",
    "    else:    \n",
    "        auc = roc_auc_score(y_valid, predictions_prob)\n",
    "\n",
    "        # Calculate the precision and recall scores\n",
    "        precision = precision_score(y_valid, predictions)\n",
    "        recall = recall_score(y_valid, predictions)\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    \n",
    "\n",
    "    return cm\n",
    "def run_simulator(gbm_model,dvalid,y_valid,rr,train,threshold):\n",
    "   # dtest = xgb.DMatrix(X_valid, label=y_valid)  \n",
    "    min_ = 1\n",
    "    max_ = 99\n",
    "    balance = 0\n",
    "    best_threshold = -1\n",
    "    if train:\n",
    "        for threshold in range(min_,max_):\n",
    "            threshold = threshold / 100\n",
    "            cm = print_results(gbm_model,dvalid,y_valid,label = 'TEST',threshold = threshold)\n",
    "            num_trades = int(cm[1][1] + cm[0][1])\n",
    "            if num_trades == 0:\n",
    "                pass\n",
    "            else:\n",
    "                win_rate = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "                loss_rate = 1 - win_rate\n",
    "\n",
    "                ev = (win_rate * rr) - (loss_rate * 1) \n",
    "                bal = 10000\n",
    "                for i in range(num_trades):\n",
    "                    bal += (bal * (ev/100))\n",
    "                    bal -= (bal * .003) #spread and commission cost\n",
    "                if bal > balance:\n",
    "                    balance = bal\n",
    "                    best_threshold = threshold\n",
    "                if balance > 10000000:\n",
    "                    balance = 10000000\n",
    "    else:\n",
    "        cm = print_results(gbm_model,dvalid,y_valid,label = 'TEST',threshold = threshold)\n",
    "        num_trades = int(cm[1][1] + cm[0][1])\n",
    "        if num_trades == 0:\n",
    "            pass\n",
    "        else:\n",
    "            win_rate = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "            loss_rate = 1 - win_rate\n",
    "\n",
    "            ev = (win_rate * rr) - (loss_rate * 1) \n",
    "            bal = 10000\n",
    "            for i in range(num_trades):\n",
    "                bal += (bal * (ev/100))\n",
    "                bal -= (bal * .003) #spread and commission cost\n",
    "            if bal > balance:\n",
    "                balance = bal\n",
    "                best_threshold = threshold\n",
    "            if balance > 10000000:\n",
    "                balance = 10000000\n",
    "    balance = round(balance)\n",
    "    print('final balance',balance,'threshold',best_threshold)\n",
    "    return balance,best_threshold\n",
    "\n",
    "def save_xgb_model(model,params,auc_score,auc_score2,train_balance,valid_balance,test_balance,balance_2022,threshold):\n",
    "    print('SAVING XGB MODEL')\n",
    "    import json\n",
    "    \n",
    "    #directory_path = os.getcwd() + \"/ML_MODEL_V3_BULLISH_\" + str(bullish) + \"_TP_\" + str(tp) + \"_SL_\" + str(sl) + \"/\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    prefix = directory_path + 'AUC_train_' + str(round(auc_score2 * 100,2)) + \\\n",
    "        '_AUC_test_' + str(round(auc_score * 100,2)) + '_SIM_BALANCE_TRAIN_' + str(train_balance) \\\n",
    "    + '_VALID_' + str(valid_balance)+ '_TEST_' + str(test_balance) + '_2022_' + str(balance_2022) + '_threshold_' + str(round(threshold,3))\n",
    "    print('saving xgb model:',prefix)\n",
    "    directory = prefix\n",
    "    isdir = os.path.isdir(directory) \n",
    "    if isdir:\n",
    "        print('DIRECTORY:',directory,' EXISTS, passing...')\n",
    "        pass\n",
    "    else:\n",
    "        print('MAKING DIRECTORY:',directory)\n",
    "        os.mkdir(directory) \n",
    "    file_name = prefix + '/xgb.pkl'\n",
    "\n",
    "    # save\n",
    "    pickle.dump(model, open(file_name, \"wb\"))\n",
    "    \n",
    "\n",
    "    \n",
    "    # open file for writing\n",
    "    f = open(prefix + '/params.json',\"w\")\n",
    "\n",
    "    # write file\n",
    "    f.write( str(params) )\n",
    "\n",
    "    # close file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    \n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_types=feature_types)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid, feature_types=feature_types)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_types=feature_types)\n",
    "    dtest2 = xgb.DMatrix(X_test2, label=y_test2, feature_types=feature_types)\n",
    "    \n",
    "    #dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    #dvalid = xgb.DMatrix(X_valid, label=y_valid)    \n",
    "    \n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm_model = xgb.train(params, dtrain, num_round, evals=watchlist,early_stopping_rounds=5, verbose_eval=True)\n",
    "    predictions = gbm_model.predict(dvalid,\n",
    "                                    ntree_limit=gbm_model.best_iteration + 1)\n",
    "    score = roc_auc_score(y_valid, predictions)    \n",
    "    # Predictions for validation and train sets\n",
    "    y_pred_valid = gbm_model.predict(dvalid, ntree_limit=gbm_model.best_iteration + 1)\n",
    "    y_pred_train = gbm_model.predict(dtrain, ntree_limit=gbm_model.best_iteration + 1)\n",
    "    \n",
    "    # Calculate metrics for validation set\n",
    "    cm_valid = confusion_matrix(y_valid, np.round(y_pred_valid))\n",
    "    f1_valid = f1_score(y_valid, np.round(y_pred_valid))\n",
    "    precision_valid = precision_score(y_valid, np.round(y_pred_valid))\n",
    "    recall_valid = recall_score(y_valid, np.round(y_pred_valid))\n",
    "    accuracy_valid = accuracy_score(y_valid, np.round(y_pred_valid))\n",
    "    auc_valid = roc_auc_score(y_valid, y_pred_valid)\n",
    "    \n",
    "    # Calculate metrics for train set\n",
    "    cm_train = confusion_matrix(y_train, np.round(y_pred_train))\n",
    "    f1_train = f1_score(y_train, np.round(y_pred_train))\n",
    "    precision_train = precision_score(y_train, np.round(y_pred_train))\n",
    "    recall_train = recall_score(y_train, np.round(y_pred_train))\n",
    "    accuracy_train = accuracy_score(y_train, np.round(y_pred_train))\n",
    "    auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    \n",
    "    \n",
    "    y_pred_test = gbm_model.predict(dtest, ntree_limit=gbm_model.best_iteration + 1)\n",
    "    auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nValidation set metrics:\")\n",
    "    print(f\"Confusion matrix:\\n{cm_valid}\")\n",
    "    print(f\"F1 score: {f1_valid}\")\n",
    "    print(f\"Precision: {precision_valid}\")\n",
    "    print(f\"Recall: {recall_valid}\")\n",
    "    print(f\"Accuracy: {accuracy_valid}\")\n",
    "    print(f\"AUC score: {auc_valid}\")\n",
    "    \n",
    "    print(\"\\nTrain set metrics:\")\n",
    "    print(f\"Confusion matrix:\\n{cm_train}\")\n",
    "    print(f\"F1 score: {f1_train}\")\n",
    "    print(f\"Precision: {precision_train}\")\n",
    "    print(f\"Recall: {recall_train}\")\n",
    "    print(f\"Accuracy: {accuracy_train}\")\n",
    "    print(f\"AUC score: {auc_train}\")\n",
    "\n",
    "    # Plot AUC chart for both validation and train sets\n",
    "    fpr_valid, tpr_valid, _ = roc_curve(y_valid, y_pred_valid)\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_train)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr_valid, tpr_valid, label=f'Validation AUC = {auc_valid:.2f}')\n",
    "    plt.plot(fpr_train, tpr_train, label=f'Train AUC = {auc_train:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plot_importance(gbm_model, title='Feature importances', xlabel='F score', ylabel='Features', importance_type='weight')\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    midpoint = 0\n",
    "    \n",
    "    if midpoint != 0:\n",
    "        print('RUNNING SIM ON TRAIN SET')\n",
    "        train_balance,threshold =  run_simulator(gbm_model,dvalid = dtrain,y_valid = y_train,rr = tp / sl,train = True,threshold = 0)\n",
    "\n",
    "        print('RUNNING SIM ON TEST SET')\n",
    "        test_balance,threshold3 =  run_simulator(gbm_model,dvalid = dtest,y_valid = y_test,rr = tp / sl,train = True,threshold = 0)\n",
    "\n",
    "        threshold_test = threshold + .05\n",
    "        print(\"2 Thresholds\",threshold,threshold3,' MIDPOINT',(threshold + threshold3) / 2)\n",
    "        threshold = (threshold + threshold3) / 2\n",
    "\n",
    "        print('RUNNING SIM ON VALID SET')\n",
    "        valid_balance,threshold_ =  run_simulator(gbm_model,dvalid = dvalid,y_valid = y_valid,rr = tp / sl,train = False,threshold = threshold)\n",
    "\n",
    "        print('RUNNING SIM ON 2022 SET')\n",
    "        balance_2022,threshold_ =  run_simulator(gbm_model,dvalid = dtest2,y_valid = y_test2,rr = tp / sl,train = False,threshold = threshold)\n",
    "\n",
    "    else:\n",
    "        print('RUNNING SIM ON TRAIN SET')\n",
    "        train_balance,threshold =  run_simulator(gbm_model,dvalid = dtrain,y_valid = y_train,rr = tp / sl,train = True,threshold = 0)\n",
    "\n",
    "        print('RUNNING SIM ON TEST SET')\n",
    "        test_balance,threshold3 =  run_simulator(gbm_model,dvalid = dtest,y_valid = y_test,rr = tp / sl,train = False,threshold = threshold)\n",
    "\n",
    "\n",
    "        print('RUNNING SIM ON VALID SET')\n",
    "        valid_balance,threshold_ =  run_simulator(gbm_model,dvalid = dvalid,y_valid = y_valid,rr = tp / sl,train = False,threshold = threshold)\n",
    "\n",
    "        print('RUNNING SIM ON 2022 SET')\n",
    "        balance_2022,threshold_ =  run_simulator(gbm_model,dvalid = dtest2,y_valid = y_test2,rr = tp / sl,train = False,threshold = threshold)\n",
    "\n",
    "                \n",
    "    \n",
    "    save_xgb_model(model = gbm_model,params = params,auc_score = score,auc_score2 = auc_train,\n",
    "                   train_balance = train_balance,valid_balance = valid_balance,test_balance = test_balance,balance_2022 = balance_2022,threshold = threshold)\n",
    "    \n",
    "    \n",
    "    auc_difference = abs(auc_train - auc_test)\n",
    "    auc_difference2 = abs(auc_train - auc_valid)\n",
    "    \n",
    "    # Penalize the validation AUC by the difference between the training and validation AUC\n",
    "    score = auc_train - (auc_difference * .3)  #(auc_difference2 * .25)##(auc_difference * .25)# - (auc_difference2 * .25)\n",
    "    #score = auc_train\n",
    "\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize(\n",
    "             trials, \n",
    "             random_state=SEED):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of \n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "    # To learn more about XGBoost parameters, head to this page: \n",
    "    # https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 25, 150, 1),\n",
    "         #'n_estimators': 10,\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        # A problem with max_depth casted to float instead of int with\n",
    "        # the hp.quniform method.\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(1, 8, dtype=int)),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "        'eval_metric': 'auc',\n",
    "        'objective': 'binary:logistic',\n",
    "        'scale_pos_weight': hp.uniform('scale_pos_weight', 1, int((y_train.shape[0] - y_train.sum()) / y_train.sum()) + 10),\n",
    "    \n",
    "        # Increase this number if you have more cores. Otherwise, remove it and it will default \n",
    "        # to the maxium number. \n",
    "        'nthread': 4,\n",
    "        'booster': 'gbtree',\n",
    "        #'tree_method': 'exact',\n",
    "        'tree_method': 'hist',\n",
    "        'silent': 1,\n",
    "        'seed': random_state\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                max_evals=100, trials=trials)\n",
    "    return best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = datetime(2005,1,1,0,0,0)\n",
    "end = datetime(2023,1,1,0,0,0)\n",
    "\n",
    "\n",
    "sl = 5\n",
    "tp = 100\n",
    "bullish = True\n",
    "spread = .5\n",
    "\n",
    "\n",
    "lst = [\n",
    "    [5,100,True],\n",
    "    [5,100,False],\n",
    "    [5,200,True],\n",
    "    [5,200,False],\n",
    "    [10,100,True],\n",
    "    [10,100,False],\n",
    "    [10,200,True],\n",
    "    [10,200,False],\n",
    "    [10,500,True],\n",
    "    [10,500,False]\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "lst = [\n",
    "    [10,500,True],\n",
    "    [10,200,True],\n",
    "    [10,100,True],\n",
    "    [5,200,True],\n",
    "    [5,100,True]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "lst = [\n",
    "    [5,200,True],\n",
    "    [5,100,True],\n",
    "    [10,200,True],\n",
    "    [10,100,True]\n",
    "        \n",
    "]\n",
    "for l in lst:\n",
    "    print(l)\n",
    "    sl = l[0]\n",
    "    tp = l[1]\n",
    "    bullish = l[2]\n",
    "\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid,X_test, X_test2, y_test, y_test2 = load_train_and_test_data(start,end,sl,tp,bullish,spread)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    feature_types = get_feature_types(X_train)\n",
    "    col = 'pair'\n",
    "    encoder.fit(X_train[col])\n",
    "    \n",
    "    directory_path = os.getcwd() + \"/ML_MODEL_REGULARIZE5_BULLISH_\" + str(bullish) + \"_TP_\" + str(tp) + \"_SL_\" + str(sl) + \"/\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "    with open(directory_path + str(date.today()) + \"_encoder.pkl\", \"wb\") as f:\n",
    "        pickle.dump(encoder, f)\n",
    "        \n",
    "    \n",
    "    X_train[col] = encoder.transform(X_train[col])\n",
    "    X_valid[col] = encoder.transform(X_valid[col])\n",
    "    X_test[col] = encoder.transform(X_test[col])\n",
    "    X_test2[col] = encoder.transform(X_test2[col])\n",
    "\n",
    "    X_train.head()\n",
    "\n",
    "\n",
    "    trials = Trials()\n",
    "    try:\n",
    "        best_hyperparams = optimize(\n",
    "                                trials\n",
    "                                )\n",
    "    except:\n",
    "        print('FAILLURE')\n",
    "    print(\"The best hyperparameters are: \", \"\\n\")\n",
    "    print(best_hyperparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model\n",
    "## ML_MODEL_REGULARIZE4_BULLISH_True_TP_200_SL_5\n",
    "## AUC_train_84.68_AUC_test_83.9_SIM_BALANCE_TRAIN_10000000_VALID_36908_TEST_10000000_2022_109258_threshold_0.78\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to extract the AUC_test score from the file name\n",
    "def get_auc_test_score(file_name):\n",
    "    match = re.search(r\"AUC_test_([\\d.]+)\", file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 0\n",
    "def load_xgb_model(model_path):\n",
    "\n",
    "    print('LOADING XGB MODEL FROM:',model_path)\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "    return model\n",
    "\n",
    "folder_path = os.getcwd() + '/ML_MODEL_V2/'  # Replace with your folder path\n",
    "file_pattern = 'SIM_BALANCE'\n",
    "# List all files in the folder and filter based on the desired string\n",
    "files = [file_name for file_name in os.listdir(folder_path) if file_pattern in file_name]\n",
    "\n",
    "# Sort the files based on the extracted AUC_test score\n",
    "sorted_files = sorted(files, key=get_auc_test_score)\n",
    "\n",
    "\n",
    "# Print the sorted file names\n",
    "for folder_name in reversed(sorted_files):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"File: {folder_name}\")\n",
    "    model_path = os.getcwd() + '/ML_MODEL_V2/' + folder_name + '/xgb.pkl'\n",
    "    gbm_model = load_xgb_model(model_path)\n",
    "    s = 100000\n",
    "    e = 200000\n",
    "    for s in [0,100000,200000]:\n",
    "        e = s + 100000\n",
    "        print(s,e)\n",
    "        dvalid = xgb.DMatrix(X_test.iloc[s:e,:], label=y_test.iloc[s:e])\n",
    "        run_simulator(gbm_model,dvalid = dvalid,y_valid = y_test.iloc[s:e])\n",
    "        \n",
    "\n",
    "        print()\n",
    "        \n",
    "    print('RUNNING FINAL HOLDOUT SET 2022...')\n",
    "    dvalid = xgb.DMatrix(X_test2, label=y_test2)\n",
    "    run_simulator(gbm_model,dvalid = dvalid,y_valid = y_test2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/aidanmcconnell/Documents/MARKET_ANALYTICS/forex/Macro/ML_MODEL_V2/AUC_train_73.38_AUC_test_69.95_SIM_BALANCE_10000000/xgb.pkl'\n",
    "gbm_model = load_xgb_model(model_path)\n",
    "\n",
    "dvalid = xgb.DMatrix(X_test2, label=y_test2)\n",
    "run_simulator(gbm_model,dvalid = dvalid,y_valid = y_test2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
